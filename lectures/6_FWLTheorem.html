<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>The FWL theorem and coefficient interpretation.</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-MMK2VCM6EW"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-MMK2VCM6EW', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">The FWL theorem and coefficient interpretation.</li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../stat_bear.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://github.com/berkeley-stat151a/fall-2024" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course_policies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Policies</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lectures/lectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lectures</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/assignments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignments</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../datasets/data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Datasets</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../quizzes/quizzes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quizzes</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#goals" id="toc-goals" class="nav-link active" data-scroll-target="#goals">Goals</a></li>
  <li><a href="#correlated-regressors" id="toc-correlated-regressors" class="nav-link" data-scroll-target="#correlated-regressors">Correlated regressors</a></li>
  <li><a href="#the-fwl-theorem" id="toc-the-fwl-theorem" class="nav-link" data-scroll-target="#the-fwl-theorem">The FWL theorem</a>
  <ul class="collapse">
  <li><a href="#the-special-case-of-a-constant-regressor" id="toc-the-special-case-of-a-constant-regressor" class="nav-link" data-scroll-target="#the-special-case-of-a-constant-regressor">The special case of a constant regressor</a></li>
  </ul></li>
  <li><a href="#data-visualization" id="toc-data-visualization" class="nav-link" data-scroll-target="#data-visualization">Data visualization</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
$$

\newcommand{\mybold}[1]{\boldsymbol{#1}} 


\newcommand{\trans}{\intercal}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\bbr}{\mathbb{R}}
\newcommand{\bbz}{\mathbb{Z}}
\newcommand{\bbc}{\mathbb{C}}
\newcommand{\gauss}[1]{\mathcal{N}\left(#1\right)}
\newcommand{\chisq}[1]{\mathcal{\chi}^2_{#1}}
\newcommand{\studentt}[1]{\mathrm{StudentT}_{#1}}
\newcommand{\fdist}[2]{\mathrm{FDist}_{#1,#2}}

\newcommand{\argmin}[1]{\underset{#1}{\mathrm{argmin}}\,}
\newcommand{\projop}[1]{\underset{#1}{\mathrm{Proj}}\,}
\newcommand{\proj}[1]{\underset{#1}{\mybold{P}}}
\newcommand{\expect}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\prob}[1]{\mathbb{P}\left(#1\right)}
\newcommand{\dens}[1]{\mathit{p}\left(#1\right)}
\newcommand{\var}[1]{\mathrm{Var}\left(#1\right)}
\newcommand{\cov}[1]{\mathrm{Cov}\left(#1\right)}
\newcommand{\sumn}{\sum_{n=1}^N}
\newcommand{\meann}{\frac{1}{N} \sumn}
\newcommand{\cltn}{\frac{1}{\sqrt{N}} \sumn}

\newcommand{\trace}[1]{\mathrm{trace}\left(#1\right)}
\newcommand{\diag}[1]{\mathrm{Diag}\left(#1\right)}
\newcommand{\grad}[2]{\nabla_{#1} \left. #2 \right.}
\newcommand{\gradat}[3]{\nabla_{#1} \left. #2 \right|_{#3}}
\newcommand{\fracat}[3]{\left. \frac{#1}{#2} \right|_{#3}}


\newcommand{\W}{\mybold{W}}
\newcommand{\w}{w}
\newcommand{\wbar}{\bar{w}}
\newcommand{\wv}{\mybold{w}}

\newcommand{\X}{\mybold{X}}
\newcommand{\x}{x}
\newcommand{\xbar}{\bar{x}}
\newcommand{\xv}{\mybold{x}}
\newcommand{\Xcov}{\Sigmam_{\X}}
\newcommand{\Xcovhat}{\hat{\Sigmam}_{\X}}
\newcommand{\Covsand}{\Sigmam_{\mathrm{sand}}}
\newcommand{\Covsandhat}{\hat{\Sigmam}_{\mathrm{sand}}}

\newcommand{\Z}{\mybold{Z}}
\newcommand{\z}{z}
\newcommand{\zv}{\mybold{z}}
\newcommand{\zbar}{\bar{z}}

\newcommand{\Y}{\mybold{Y}}
\newcommand{\Yhat}{\hat{\Y}}
\newcommand{\y}{y}
\newcommand{\yv}{\mybold{y}}
\newcommand{\yhat}{\hat{\y}}
\newcommand{\ybar}{\bar{y}}

\newcommand{\res}{\varepsilon}
\newcommand{\resv}{\mybold{\res}}
\newcommand{\resvhat}{\hat{\mybold{\res}}}
\newcommand{\reshat}{\hat{\res}}

\newcommand{\betav}{\mybold{\beta}}
\newcommand{\betavhat}{\hat{\betav}}
\newcommand{\betahat}{\hat{\beta}}
\newcommand{\betastar}{{\beta^{*}}}


\newcommand{\f}{f}
\newcommand{\fhat}{\hat{f}}

\newcommand{\bv}{\mybold{\b}}
\newcommand{\bvhat}{\hat{\bv}}

\newcommand{\alphav}{\mybold{\alpha}}
\newcommand{\alphavhat}{\hat{\av}}
\newcommand{\alphahat}{\hat{\alpha}}

\newcommand{\omegav}{\mybold{\omega}}

\newcommand{\gv}{\mybold{\gamma}}
\newcommand{\gvhat}{\hat{\gv}}
\newcommand{\ghat}{\hat{\gamma}}

\newcommand{\hv}{\mybold{\h}}
\newcommand{\hvhat}{\hat{\hv}}
\newcommand{\hhat}{\hat{\h}}

\newcommand{\gammav}{\mybold{\gamma}}
\newcommand{\gammavhat}{\hat{\gammav}}
\newcommand{\gammahat}{\hat{\gamma}}

\newcommand{\new}{\mathrm{new}}
\newcommand{\zerov}{\mybold{0}}
\newcommand{\onev}{\mybold{1}}
\newcommand{\id}{\mybold{I}}

\newcommand{\sigmahat}{\hat{\sigma}}


\newcommand{\etav}{\mybold{\eta}}
\newcommand{\muv}{\mybold{\mu}}
\newcommand{\Sigmam}{\mybold{\Sigma}}

\newcommand{\rdom}[1]{\mathbb{R}^{#1}}

\newcommand{\RV}[1]{\tilde{#1}}



\def\A{\mybold{A}}

\def\A{\mybold{A}}
\def\av{\mybold{a}}
\def\a{a}

\def\B{\mybold{B}}
\def\b{b}


\def\S{\mybold{S}}
\def\sv{\mybold{s}}
\def\s{s}

\def\R{\mybold{R}}
\def\rv{\mybold{r}}
\def\r{r}

\def\V{\mybold{V}}
\def\vv{\mybold{v}}
\def\v{v}

\def\U{\mybold{U}}
\def\uv{\mybold{u}}
\def\u{u}

\def\W{\mybold{W}}
\def\wv{\mybold{w}}
\def\w{w}

\def\tv{\mybold{t}}
\def\t{t}

\def\Sc{\mathcal{S}}
\def\ev{\mybold{e}}

\def\Lammat{\mybold{\Lambda}}

\def\Q{\mybold{Q}}

$$

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">The FWL theorem and coefficient interpretation.</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="goals" class="level1">
<h1>Goals</h1>
<ul>
<li>Discuss the FWL theorem and some uses and consequences
<ul>
<li>Inclusion of a constant</li>
<li>Linear regression as the marginal association</li>
<li>The FWL theorem for visualization</li>
</ul></li>
</ul>
</section>
<section id="correlated-regressors" class="level1">
<h1>Correlated regressors</h1>
<p>Take <span class="math inline">\(\X = (\xv_1, \ldots, \xv_P)\)</span>, where <span class="math inline">\(\xv_1 = \onev\)</span>, so that we are regressing on <span class="math inline">\(P-1\)</span> regressors and a constant. If the regressors are all orthogonal to one another (<span class="math inline">\(\xv_k^\trans \xv_j = 0\)</span> for <span class="math inline">\(k \ne j\)</span>), then we know that</p>
<p><span class="math display">\[
\betahat = (\X^\trans\X)^{-1} \X^\trans \Y =
\begin{pmatrix}
\xv_1^\trans \xv_1 &amp; 0 &amp; \ldots 0 \\
0 &amp; \ddots &amp;  0 \\
0 &amp;  \ldots &amp;  \xv_P^\trans \xv_P  \\
\end{pmatrix}^{-1}
\begin{pmatrix}
\xv_1^\trans \Y \\
\vdots \\
\xv_P^\trans \Y \\
\end{pmatrix}
=
\begin{pmatrix}
\frac{\xv_1^\trans \Y}{\xv_1^\trans \xv_1} \\
\vdots \\
\frac{\xv_P^\trans \Y}{\xv_P^\trans \xv_P} \\
\end{pmatrix}.
\]</span></p>
<div class="callout callout-style-default callout-warning callout-titled" title="Exercise">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the limiting behavior of <span class="math inline">\(\frac{1}{N}\X^\trans \X\)</span> when the <span class="math inline">\(\xv_n\)</span> are independent of one another? What if they are independent and <span class="math inline">\(\expect{\xv_n} = 0\)</span>, except for a constant <span class="math inline">\(\xv_{n1} = 1\)</span>?</p>
</div>
</div>
<p>However, typically the regressors are not orthogonal to one another. When they are not, we can ask</p>
<ul>
<li>How can we interpret the coefficients?</li>
<li>How does the relation between the regressors affect the <span class="math inline">\(\betavhat\)</span> covariance matrix?</li>
</ul>
</section>
<section id="the-fwl-theorem" class="level1">
<h1>The FWL theorem</h1>
<p>The FWL theorem gives an expression for sub-vectors of <span class="math inline">\(\betavhat\)</span>. Specifically, let’s partition our regressors into two sets:</p>
<p><span class="math inline">\(\y_n \sim \xv_n^\trans \beta = \av_{n}^\trans \betav_a + \bv_{n}^\trans \betav_b\)</span>,</p>
<p>where <span class="math inline">\(\betav^\trans = (\betav_a^\trans, \betav_b^\trans)\)</span> and <span class="math inline">\(\xv_n^\trans = (\av_n^\trans, \bv_n^\trans)\)</span>. We can similarly partition our regressors matrix into two parts <span class="math display">\[
\X = (\X_a \, \X_b).
\]</span></p>
<p>A particular example to keep in mind is where</p>
<p><span class="math display">\[
\begin{aligned}
\xv_n^\trans =&amp; (\x_{n2}, \ldots, \x_{n(P-1)}, 1)^\trans \\
\bv_n =&amp; (1) \\
\av_n^\trans =&amp; (\x_{n2}, \ldots, \x_{n(P-1)})^\trans \\
\end{aligned}
\]</span></p>
<p>Let us ask what is the effect on <span class="math inline">\(\betav_a\)</span> of including <span class="math inline">\(\bv_n\)</span> as a regressor?<br>
The answer is given by the FWL theorem. Recall that</p>
<p><span class="math display">\[
\resvhat = \Y - \X\betavhat = \Y - \X_a \betavhat_a - \X_b \betavhat_b,
\]</span></p>
<p>and that <span class="math inline">\(\X^\trans \resvhat = \zerov\)</span>, so <span class="math inline">\(\X_a^\trans \resvhat = \zerov\)</span> and <span class="math inline">\(\X_b^\trans \resvhat = \zerov\)</span>. Recall also the definition of the projection matrix perpendicular to the span of <span class="math inline">\(\X_b\)</span>:</p>
<p><span class="math display">\[
\proj{\X_b^\perp} := \id{} - \X_b (\X_b^\trans \X_b)^{-1} \X_b^\trans.
\]</span></p>
<p>Applying <span class="math inline">\(\proj{\X_b^\perp}\)</span> to both sides of <span class="math inline">\(\resvhat = \Y - \X\betavhat\)</span> gives</p>
<p><span class="math display">\[
\proj{\X_b^\perp} \resvhat = \resvhat = \proj{\X_b^\perp} \Y - \proj{\X_b^\perp} \X_a \betavhat_a - \proj{\X_b^\perp} \X_b \betavhat_b
= \proj{\X_b^\perp} \Y - \proj{\X_b^\perp} \X_a \betavhat_a.
\]</span></p>
<div class="callout callout-style-default callout-warning callout-titled" title="Exercise">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>Verify that <span class="math inline">\(\proj{\X_b^\perp} \resvhat = \resvhat\)</span> and <span class="math inline">\(\proj{\X_b^\perp} \X_b \betavhat_b = \zerov\)</span>.</p>
</div>
</div>
<p>Now appying <span class="math inline">\((\proj{\X_b^\perp} \X_a)^\trans\)</span> to both sides of the preceding expression gives</p>
<p><span class="math display">\[
\begin{aligned}
\X_a^\trans \resvhat ={}&amp; \zerov = \X_a^\trans \proj{\X_b^\perp} \Y - \X_a^\trans \proj{\X_b^\perp} \X_a \betavhat_a
  \quad \Rightarrow \\
\left(\proj{\X_b^\perp} \X_a \right)^\trans
  \proj{\X_b^\perp} \X_a \betavhat_a  ={}&amp;  
\left(\proj{\X_b^\perp} \X_a \right)^\trans \proj{\X_b^\perp} \Y
\end{aligned}
\]</span></p>
<p>If we assume that <span class="math inline">\(\X\)</span> is full-rank, then <span class="math inline">\(\proj{\X_b^\perp} \X_a\)</span> must be full-rank as well, since otherwise one of the columns of <span class="math inline">\(\X_a\)</span> would be a linear combination of columns of <span class="math inline">\(\X_b\)</span>. Therefore we can invert to get</p>
<p><span class="math display">\[
\betavhat_a = \left((\proj{\X_b^\perp} \X_a)^\trans \proj{\X_b^\perp} \X_a \right)^{-1}
\left(\proj{\X_b^\perp} \X_a \right)^\trans \proj{\X_b^\perp} \Y.
\]</span></p>
<p>This is exactly the same as the linear regression</p>
<p><span class="math display">\[
\tilde{\Y} \sim \tilde{\X_a} \betav_a \quad\textrm{where }
\tilde{\X_a} := \proj{\X_b^\perp} \X_a \textrm{ and } \tilde{\Y} := \proj{\X_b^\perp} \Y.
\]</span></p>
<p>That is, the OLS coefficient on <span class="math inline">\(\X_a\)</span> is the same as projecting all the responses and regressors to a space orthogonal to <span class="math inline">\(\X_b\)</span>, and running ordinary regression.</p>
<p>See <a href="https://arxiv.org/pdf/2401.00649.pdf">section 7.3 of Prof.&nbsp;Ding’s book</a> for a more rigorous proof, which uses the Schur representation of sub-matrices of <span class="math inline">\((\X^\trans \X)^{-1}\)</span>.</p>
<section id="the-special-case-of-a-constant-regressor" class="level3">
<h3 class="anchored" data-anchor-id="the-special-case-of-a-constant-regressor">The special case of a constant regressor</h3>
<p>Suppose we want to regress <span class="math inline">\(\Y \sim \beta_0 + \betav^\trans \xv_n\)</span>. We’d like to know what <span class="math inline">\(\betavhat\)</span> is, and in particular, what is the effect of including a constant.</p>
<p>We can answer this with the FWL theorem by taking <span class="math inline">\(\bv_n = (1)\)</span> and <span class="math inline">\(\av_n = \xv_n\)</span>. Then <span class="math inline">\(\betavhat\)</span> will be the same as in the regression</p>
<p><span class="math display">\[
\tilde{Y} \sim \tilde{X} \betav
\]</span></p>
<p>where <span class="math inline">\(\tilde{Y} = \proj{\X_b^\perp} \Y\)</span> and <span class="math inline">\(\tilde{X} = \proj{\X_b^\perp} \X\)</span>.</p>
<p>A particular special case is useful for intuition. Take <span class="math inline">\(\xv_b\)</span> to simply be the constant regressor, <span class="math inline">\(1\)</span>. Then <span class="math inline">\(\X_b = \onev\)</span>, and</p>
<p><span class="math display">\[
\proj{\X_b^\perp} = \id{} - \onev (\onev^\trans \onev)^{-1} \onev^\trans = \id{} - \frac{1}{N} \onev \onev^\trans.
\]</span></p>
<p><span class="math inline">\(\onev^\trans \onev = \sumn 1 \cdot 1 = N\)</span></p>
<p>If we take</p>
<p><span class="math display">\[
\begin{aligned}
\onev^\trans \Y =&amp; \sumn 1 \cdot \y_n = \sumn \y_n\\
\frac{1}{N} \onev^\trans \Y =&amp; \meann 1 \cdot \y_n = \meann \y_n = \ybar\\
\onev \frac{1}{N} \onev^\trans \Y =&amp; \onev \ybar =
\begin{pmatrix}
\ybar \\
\vdots \\
\ybar
\end{pmatrix} \\
\proj{\X_b^\perp}  \Y =
\left(\id - \onev \frac{1}{N} \onev^\trans \right) \Y =&amp;
\Y - \begin{pmatrix}
\ybar \\
\vdots \\
\ybar
\end{pmatrix}
= \begin{pmatrix}
y_1 - \ybar \\
y_2 - \ybar \\
\vdots \\
y_N - \ybar
\end{pmatrix}
\end{aligned}
\]</span></p>
<p>The projection matrix <span class="math inline">\(\proj{\X_b^\perp}\)</span> thus simply centers a vector at its sample mean.</p>
<p>Similarly,</p>
<p><span class="math display">\[
\tilde{\X_a} := \proj{\X_b^\perp} \X_a = \X_a - \frac{1}{N} \onev \onev^\trans \X_a
= \X_a - \onev \xbar^\trans \\
\textrm{ where } \xbar^\trans := \begin{pmatrix} \meann \x_{n1} &amp; \ldots &amp; \meann \x_{n(P-1)} \end{pmatrix},
\]</span></p>
<p>so that the <span class="math inline">\(n\)</span>–th row of <span class="math inline">\(\proj{\X_b^\perp} \X_a\)</span> is simply <span class="math inline">\(\xv_n^\trans - \xbar^\trans\)</span>, and each regressor is centered. So</p>
<p><span class="math display">\[
\betavhat_a = (\tilde{\X_a}^\trans \tilde{\X_a})^\trans \tilde{\X_a}^\trans \tilde{\Y},
\]</span></p>
<p>the OLS estimator where <em>both the regressors and responses have been centered at their sample means</em>. In this case, by the LLN,</p>
<p><span class="math display">\[
\frac{1}{N} \tilde{\X_a}^\trans \tilde{\X_a} \rightarrow \cov{\xv_n},
\]</span></p>
<p>in contrast to the general case, where</p>
<p><span class="math display">\[
\frac{1}{N} \X^\trans \X \rightarrow \expect{\xv_n \xv_n^\trans} = \cov{\xv_n} + \expect{\xv_n}\expect{\xv_n^\trans}.
\]</span></p>
<p>For this reason, when thinking about the sampling behavior of OLS coefficients where a constant is included in the regression, it’s enough to think about the covariance of the regressors, rather than the outer product.</p>
<div class="callout callout-style-default callout-warning callout-titled" title="Exercise">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>Derive our simple least squares estimator of <span class="math inline">\(\betavhat\)</span> using the FWL theorem.</p>
</div>
</div>
</section>
</section>
<section id="data-visualization" class="level1">
<h1>Data visualization</h1>
<p>The FWL theorem can be useful for data visualization. Consider using our births dataset to investigate the relationship between smoking and baby birth weight.</p>
<div class="cell" data-display="false">
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.4.4     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors

Attaching package: 'gridExtra'


The following object is masked from 'package:dplyr':

    combine</code></pre>
</div>
</div>
<p>Here, <code>habit</code> is a one-hot indicator for whether a mother smokes, and <code>weight</code> refers to the birthweight of the baby. The following two regressions give different answers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>lm_base <span class="ot">&lt;-</span> <span class="fu">lm</span>(weight <span class="sc">~</span> habit, births_df, <span class="at">y=</span><span class="cn">TRUE</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>lm_inter <span class="ot">&lt;-</span> <span class="fu">lm</span>(weight <span class="sc">~</span> mage <span class="sc">+</span> (habit <span class="sc">+</span> whitemom <span class="sc">+</span> sex)<span class="sc">^</span><span class="dv">2</span>, births_df)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_base)<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              Estimate Std. Error    t value     Pr(&gt;|t|)
(Intercept)  7.3131742 0.04474831 163.429046 0.000000e+00
habitsmoker -0.5483355 0.13670836  -4.010987 6.568621e-05</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_inter)<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                             Estimate  Std. Error    t value      Pr(&gt;|t|)
(Intercept)                6.44074944 0.253956693 25.3616054 2.157650e-106
mage                       0.01584889 0.007444381  2.1289733  3.354004e-02
habitsmoker               -0.82153897 0.381515891 -2.1533545  3.156822e-02
whitemomwhite              0.30616770 0.143738251  2.1300364  3.345192e-02
sexmale                    0.19580339 0.182780429  1.0712492  2.843579e-01
habitsmoker:whitemomwhite  0.26039942 0.372205866  0.6996113  4.843593e-01
habitsmoker:sexmale        0.06608159 0.270569454  0.2442315  8.071098e-01
whitemomwhite:sexmale      0.18854123 0.204695257  0.9210826  3.572656e-01</code></pre>
</div>
</div>
<p>The base regression can be visualized with a simple histogram.</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.
ℹ Please use `after_stat(density)` instead.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="6_FWLTheorem_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>It makes sense that the second one is somehow controlling for other variables, but how can we visualize this?</p>
<p>Using the FWL theorem, we know that the regression in the second case is equivalent to first projecting orthogonal to all the other regressors, and then looking at the two group means. We can project orthongal with another regression that <em>excludes</em> <code>habit</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>proj_perp <span class="ot">&lt;-</span> <span class="fu">lm</span>(weight <span class="sc">~</span> mage <span class="sc">+</span> (habit <span class="sc">+</span> whitemom <span class="sc">+</span> sex)<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> habit, births_df)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(proj_perp)<span class="sc">$</span>coefficients <span class="co"># Smoker is missing</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                                 Estimate  Std. Error    t value      Pr(&gt;|t|)
(Intercept)                    6.44074944 0.253956693 25.3616054 2.157650e-106
mage                           0.01584889 0.007444381  2.1289733  3.354004e-02
whitemomwhite                  0.30616770 0.143738251  2.1300364  3.345192e-02
sexmale                        0.19580339 0.182780429  1.0712492  2.843579e-01
habitsmoker:whitemomnot white -0.82153897 0.381515891 -2.1533545  3.156822e-02
habitsmoker:whitemomwhite     -0.56113955 0.204541405 -2.7434032  6.207127e-03
habitsmoker:sexmale            0.06608159 0.270569454  0.2442315  8.071098e-01
whitemomwhite:sexmale          0.18854123 0.204695257  0.9210826  3.572656e-01</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb12" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "The FWL theorem and coefficient interpretation."</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: false</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">    include-before-body:</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">     - file: ../macros.md</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="fu"># Goals</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Discuss the FWL theorem and some uses and consequences</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Inclusion of a constant</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Linear regression as the marginal association</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>The FWL theorem for visualization</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="fu"># Correlated regressors</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>Take $\X = (\xv_1, \ldots, \xv_P)$, where $\xv_1 = \onev$, </span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>so that we are regressing on $P-1$ regressors and a constant.  If the regressors are all orthogonal to</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>one another ($\xv_k^\trans \xv_j = 0$ for $k \ne j$), then we know that</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>\betahat = (\X^\trans\X)^{-1} \X^\trans \Y = </span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>\begin{pmatrix}</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>\xv_1^\trans \xv_1 &amp; 0 &amp; \ldots 0 <span class="sc">\\</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>0 &amp; \ddots &amp;  0 <span class="sc">\\</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>0 &amp;  \ldots &amp;  \xv_P^\trans \xv_P  <span class="sc">\\</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>\end{pmatrix}^{-1}</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>\begin{pmatrix}</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>\xv_1^\trans \Y <span class="sc">\\</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>\vdots <span class="sc">\\</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>\xv_P^\trans \Y <span class="sc">\\</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>\end{pmatrix}</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>=</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>\begin{pmatrix}</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>\frac{\xv_1^\trans \Y}{\xv_1^\trans \xv_1} <span class="sc">\\</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>\vdots <span class="sc">\\</span></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>\frac{\xv_P^\trans \Y}{\xv_P^\trans \xv_P} <span class="sc">\\</span></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>\end{pmatrix}.</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning title='Exercise'} </span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>What is the limiting behavior of $\frac{1}{N}\X^\trans \X$ when the</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>$\xv_n$ are independent of one another?  What if they are</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>independent and $\expect{\xv_n} = 0$, except for a constant</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>$\xv_{n1} = 1$?</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>However, typically the regressors are not orthogonal to one another.</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>When they are not, we can ask</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How can we interpret the coefficients?</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How does the relation between the regressors affect the $\betavhat$ covariance matrix?</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a><span class="fu"># The FWL theorem</span></span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>The FWL theorem gives an expression for sub-vectors of $\betavhat$.  Specifically,</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a>let's partition our regressors into two sets:</span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a>$\y_n \sim \xv_n^\trans \beta = \av_{n}^\trans \betav_a + \bv_{n}^\trans \betav_b$, </span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a>where $\betav^\trans = (\betav_a^\trans, \betav_b^\trans)$ and $\xv_n^\trans = (\av_n^\trans, \bv_n^\trans)$.</span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>We can similarly partition our regressors matrix into two parts</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>\X = (\X_a \, \X_b).</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>A particular example to keep in mind is where</span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a>\xv_n^\trans =&amp; (\x_{n2}, \ldots, \x_{n(P-1)}, 1)^\trans <span class="sc">\\</span></span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a>\bv_n =&amp; (1) <span class="sc">\\</span></span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a>\av_n^\trans =&amp; (\x_{n2}, \ldots, \x_{n(P-1)})^\trans <span class="sc">\\</span></span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a>Let us ask what is the effect on $\betav_a$ of including $\bv_n$ as a regressor?  </span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a>The answer is given by the FWL theorem.  Recall that</span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a>\resvhat = \Y - \X\betavhat = \Y - \X_a \betavhat_a - \X_b \betavhat_b,</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a>and that $\X^\trans \resvhat = \zerov$, so</span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a>$\X_a^\trans \resvhat = \zerov$ and $\X_b^\trans \resvhat = \zerov$.</span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a>Recall also the definition of the projection matrix perpendicular</span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a>to the span of $\X_b$:</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a>\proj{\X_b^\perp} := \id{} - \X_b (\X_b^\trans \X_b)^{-1} \X_b^\trans.</span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-104"><a href="#cb12-104" aria-hidden="true" tabindex="-1"></a>Applying $\proj{\X_b^\perp}$ to both sides of $\resvhat = \Y - \X\betavhat$</span>
<span id="cb12-105"><a href="#cb12-105" aria-hidden="true" tabindex="-1"></a>gives</span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-108"><a href="#cb12-108" aria-hidden="true" tabindex="-1"></a>\proj{\X_b^\perp} \resvhat = \resvhat = \proj{\X_b^\perp} \Y - \proj{\X_b^\perp} \X_a \betavhat_a - \proj{\X_b^\perp} \X_b \betavhat_b</span>
<span id="cb12-109"><a href="#cb12-109" aria-hidden="true" tabindex="-1"></a>= \proj{\X_b^\perp} \Y - \proj{\X_b^\perp} \X_a \betavhat_a.</span>
<span id="cb12-110"><a href="#cb12-110" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-111"><a href="#cb12-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-112"><a href="#cb12-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-113"><a href="#cb12-113" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning title='Exercise'} </span>
<span id="cb12-114"><a href="#cb12-114" aria-hidden="true" tabindex="-1"></a>Verify that $\proj{\X_b^\perp} \resvhat = \resvhat$ and $\proj{\X_b^\perp} \X_b \betavhat_b = \zerov$.</span>
<span id="cb12-115"><a href="#cb12-115" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-116"><a href="#cb12-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-117"><a href="#cb12-117" aria-hidden="true" tabindex="-1"></a>Now appying $(\proj{\X_b^\perp} \X_a)^\trans$ to both sides of the preceding expression gives</span>
<span id="cb12-118"><a href="#cb12-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-119"><a href="#cb12-119" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-120"><a href="#cb12-120" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-121"><a href="#cb12-121" aria-hidden="true" tabindex="-1"></a>\X_a^\trans \resvhat ={}&amp; \zerov = \X_a^\trans \proj{\X_b^\perp} \Y - \X_a^\trans \proj{\X_b^\perp} \X_a \betavhat_a</span>
<span id="cb12-122"><a href="#cb12-122" aria-hidden="true" tabindex="-1"></a>  \quad \Rightarrow <span class="sc">\\</span></span>
<span id="cb12-123"><a href="#cb12-123" aria-hidden="true" tabindex="-1"></a>\left(\proj{\X_b^\perp} \X_a \right)^\trans </span>
<span id="cb12-124"><a href="#cb12-124" aria-hidden="true" tabindex="-1"></a>  \proj{\X_b^\perp} \X_a \betavhat_a  ={}&amp;  </span>
<span id="cb12-125"><a href="#cb12-125" aria-hidden="true" tabindex="-1"></a>\left(\proj{\X_b^\perp} \X_a \right)^\trans \proj{\X_b^\perp} \Y </span>
<span id="cb12-126"><a href="#cb12-126" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-127"><a href="#cb12-127" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-128"><a href="#cb12-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-129"><a href="#cb12-129" aria-hidden="true" tabindex="-1"></a>If we assume that $\X$ is full-rank, then $\proj{\X_b^\perp} \X_a$ must be full-rank as well, since otherwise</span>
<span id="cb12-130"><a href="#cb12-130" aria-hidden="true" tabindex="-1"></a>one of the columns of $\X_a$ would be a linear combination of columns of $\X_b$.  Therefore we can invert</span>
<span id="cb12-131"><a href="#cb12-131" aria-hidden="true" tabindex="-1"></a>to get</span>
<span id="cb12-132"><a href="#cb12-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-133"><a href="#cb12-133" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-134"><a href="#cb12-134" aria-hidden="true" tabindex="-1"></a>\betavhat_a = \left((\proj{\X_b^\perp} \X_a)^\trans \proj{\X_b^\perp} \X_a \right)^{-1} </span>
<span id="cb12-135"><a href="#cb12-135" aria-hidden="true" tabindex="-1"></a>\left(\proj{\X_b^\perp} \X_a \right)^\trans \proj{\X_b^\perp} \Y.</span>
<span id="cb12-136"><a href="#cb12-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-137"><a href="#cb12-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-138"><a href="#cb12-138" aria-hidden="true" tabindex="-1"></a>This is exactly the same as the linear regression</span>
<span id="cb12-139"><a href="#cb12-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-140"><a href="#cb12-140" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-141"><a href="#cb12-141" aria-hidden="true" tabindex="-1"></a>\tilde{\Y} \sim \tilde{\X_a} \betav_a \quad\textrm{where } </span>
<span id="cb12-142"><a href="#cb12-142" aria-hidden="true" tabindex="-1"></a>\tilde{\X_a} := \proj{\X_b^\perp} \X_a \textrm{ and } \tilde{\Y} := \proj{\X_b^\perp} \Y.</span>
<span id="cb12-143"><a href="#cb12-143" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-144"><a href="#cb12-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-145"><a href="#cb12-145" aria-hidden="true" tabindex="-1"></a>That is, the OLS coefficient on $\X_a$ is the same as projecting all the responses</span>
<span id="cb12-146"><a href="#cb12-146" aria-hidden="true" tabindex="-1"></a>and regressors to a space orthogonal to $\X_b$, and running ordinary regression.</span>
<span id="cb12-147"><a href="#cb12-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-148"><a href="#cb12-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-149"><a href="#cb12-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-150"><a href="#cb12-150" aria-hidden="true" tabindex="-1"></a>See <span class="co">[</span><span class="ot">section 7.3 of Prof. Ding's book</span><span class="co">](https://arxiv.org/pdf/2401.00649.pdf)</span> for a more rigorous proof,</span>
<span id="cb12-151"><a href="#cb12-151" aria-hidden="true" tabindex="-1"></a>which uses the Schur representation of sub-matrices of $(\X^\trans \X)^{-1}$.</span>
<span id="cb12-152"><a href="#cb12-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-153"><a href="#cb12-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-154"><a href="#cb12-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-155"><a href="#cb12-155" aria-hidden="true" tabindex="-1"></a><span class="fu">### The special case of a constant regressor</span></span>
<span id="cb12-156"><a href="#cb12-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-157"><a href="#cb12-157" aria-hidden="true" tabindex="-1"></a>Suppose we want to regress $\Y \sim \beta_0 + \betav^\trans \xv_n$.  We'd like </span>
<span id="cb12-158"><a href="#cb12-158" aria-hidden="true" tabindex="-1"></a>to know what $\betavhat$ is, and in particular, what is the effect of including </span>
<span id="cb12-159"><a href="#cb12-159" aria-hidden="true" tabindex="-1"></a>a constant.</span>
<span id="cb12-160"><a href="#cb12-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-161"><a href="#cb12-161" aria-hidden="true" tabindex="-1"></a>We can answer this with the FWL theorem by taking $\bv_n = (1)$ and</span>
<span id="cb12-162"><a href="#cb12-162" aria-hidden="true" tabindex="-1"></a>$\av_n = \xv_n$.  Then $\betavhat$ will be the same as in the regression</span>
<span id="cb12-163"><a href="#cb12-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-164"><a href="#cb12-164" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-165"><a href="#cb12-165" aria-hidden="true" tabindex="-1"></a>\tilde{Y} \sim \tilde{X} \betav</span>
<span id="cb12-166"><a href="#cb12-166" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-167"><a href="#cb12-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-168"><a href="#cb12-168" aria-hidden="true" tabindex="-1"></a>where $\tilde{Y} = \proj{\X_b^\perp} \Y$ and $\tilde{X} = \proj{\X_b^\perp} \X$.</span>
<span id="cb12-169"><a href="#cb12-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-170"><a href="#cb12-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-171"><a href="#cb12-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-172"><a href="#cb12-172" aria-hidden="true" tabindex="-1"></a>A particular special case is useful for intuition.  Take $\xv_b$ to simply be the constant</span>
<span id="cb12-173"><a href="#cb12-173" aria-hidden="true" tabindex="-1"></a>regressor, $1$.  Then $\X_b = \onev$, and</span>
<span id="cb12-174"><a href="#cb12-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-175"><a href="#cb12-175" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-176"><a href="#cb12-176" aria-hidden="true" tabindex="-1"></a>\proj{\X_b^\perp} = \id{} - \onev (\onev^\trans \onev)^{-1} \onev^\trans = \id{} - \frac{1}{N} \onev \onev^\trans.</span>
<span id="cb12-177"><a href="#cb12-177" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-178"><a href="#cb12-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-179"><a href="#cb12-179" aria-hidden="true" tabindex="-1"></a>$\onev^\trans \onev = \sumn 1 \cdot 1 = N$</span>
<span id="cb12-180"><a href="#cb12-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-181"><a href="#cb12-181" aria-hidden="true" tabindex="-1"></a>If we take</span>
<span id="cb12-182"><a href="#cb12-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-183"><a href="#cb12-183" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-184"><a href="#cb12-184" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb12-185"><a href="#cb12-185" aria-hidden="true" tabindex="-1"></a>\onev^\trans \Y =&amp; \sumn 1 \cdot \y_n = \sumn \y_n<span class="sc">\\</span></span>
<span id="cb12-186"><a href="#cb12-186" aria-hidden="true" tabindex="-1"></a>\frac{1}{N} \onev^\trans \Y =&amp; \meann 1 \cdot \y_n = \meann \y_n = \ybar<span class="sc">\\</span></span>
<span id="cb12-187"><a href="#cb12-187" aria-hidden="true" tabindex="-1"></a>\onev \frac{1}{N} \onev^\trans \Y =&amp; \onev \ybar =</span>
<span id="cb12-188"><a href="#cb12-188" aria-hidden="true" tabindex="-1"></a>\begin{pmatrix}</span>
<span id="cb12-189"><a href="#cb12-189" aria-hidden="true" tabindex="-1"></a>\ybar <span class="sc">\\</span></span>
<span id="cb12-190"><a href="#cb12-190" aria-hidden="true" tabindex="-1"></a>\vdots <span class="sc">\\</span></span>
<span id="cb12-191"><a href="#cb12-191" aria-hidden="true" tabindex="-1"></a>\ybar</span>
<span id="cb12-192"><a href="#cb12-192" aria-hidden="true" tabindex="-1"></a>\end{pmatrix} <span class="sc">\\</span></span>
<span id="cb12-193"><a href="#cb12-193" aria-hidden="true" tabindex="-1"></a>\proj{\X_b^\perp}  \Y = </span>
<span id="cb12-194"><a href="#cb12-194" aria-hidden="true" tabindex="-1"></a>\left(\id - \onev \frac{1}{N} \onev^\trans \right) \Y =&amp;</span>
<span id="cb12-195"><a href="#cb12-195" aria-hidden="true" tabindex="-1"></a>\Y - \begin{pmatrix}</span>
<span id="cb12-196"><a href="#cb12-196" aria-hidden="true" tabindex="-1"></a>\ybar <span class="sc">\\</span></span>
<span id="cb12-197"><a href="#cb12-197" aria-hidden="true" tabindex="-1"></a>\vdots <span class="sc">\\</span></span>
<span id="cb12-198"><a href="#cb12-198" aria-hidden="true" tabindex="-1"></a>\ybar</span>
<span id="cb12-199"><a href="#cb12-199" aria-hidden="true" tabindex="-1"></a>\end{pmatrix}</span>
<span id="cb12-200"><a href="#cb12-200" aria-hidden="true" tabindex="-1"></a>= \begin{pmatrix}</span>
<span id="cb12-201"><a href="#cb12-201" aria-hidden="true" tabindex="-1"></a>y_1 - \ybar <span class="sc">\\</span></span>
<span id="cb12-202"><a href="#cb12-202" aria-hidden="true" tabindex="-1"></a>y_2 - \ybar <span class="sc">\\</span></span>
<span id="cb12-203"><a href="#cb12-203" aria-hidden="true" tabindex="-1"></a>\vdots <span class="sc">\\</span></span>
<span id="cb12-204"><a href="#cb12-204" aria-hidden="true" tabindex="-1"></a>y_N - \ybar</span>
<span id="cb12-205"><a href="#cb12-205" aria-hidden="true" tabindex="-1"></a>\end{pmatrix}</span>
<span id="cb12-206"><a href="#cb12-206" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb12-207"><a href="#cb12-207" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-208"><a href="#cb12-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-209"><a href="#cb12-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-210"><a href="#cb12-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-211"><a href="#cb12-211" aria-hidden="true" tabindex="-1"></a>The projection matrix $\proj{\X_b^\perp}$ thus simply centers a vector at its sample mean.</span>
<span id="cb12-212"><a href="#cb12-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-213"><a href="#cb12-213" aria-hidden="true" tabindex="-1"></a>Similarly,</span>
<span id="cb12-214"><a href="#cb12-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-215"><a href="#cb12-215" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-216"><a href="#cb12-216" aria-hidden="true" tabindex="-1"></a>\tilde{\X_a} := \proj{\X_b^\perp} \X_a = \X_a - \frac{1}{N} \onev \onev^\trans \X_a</span>
<span id="cb12-217"><a href="#cb12-217" aria-hidden="true" tabindex="-1"></a>= \X_a - \onev \xbar^\trans <span class="sc">\\</span></span>
<span id="cb12-218"><a href="#cb12-218" aria-hidden="true" tabindex="-1"></a>\textrm{ where } \xbar^\trans := \begin{pmatrix} \meann \x_{n1} &amp; \ldots &amp; \meann \x_{n(P-1)} \end{pmatrix},</span>
<span id="cb12-219"><a href="#cb12-219" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-220"><a href="#cb12-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-221"><a href="#cb12-221" aria-hidden="true" tabindex="-1"></a>so that the $n$--th row of $\proj{\X_b^\perp} \X_a$ is simply $\xv_n^\trans - \xbar^\trans$, and</span>
<span id="cb12-222"><a href="#cb12-222" aria-hidden="true" tabindex="-1"></a>each regressor is centered.  So </span>
<span id="cb12-223"><a href="#cb12-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-224"><a href="#cb12-224" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-225"><a href="#cb12-225" aria-hidden="true" tabindex="-1"></a>\betavhat_a = (\tilde{\X_a}^\trans \tilde{\X_a})^\trans \tilde{\X_a}^\trans \tilde{\Y}, </span>
<span id="cb12-226"><a href="#cb12-226" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-227"><a href="#cb12-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-228"><a href="#cb12-228" aria-hidden="true" tabindex="-1"></a>the OLS estimator where *both the regressors and responses have been centered at their sample means*.</span>
<span id="cb12-229"><a href="#cb12-229" aria-hidden="true" tabindex="-1"></a>In this case, by the LLN,</span>
<span id="cb12-230"><a href="#cb12-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-231"><a href="#cb12-231" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-232"><a href="#cb12-232" aria-hidden="true" tabindex="-1"></a>\frac{1}{N} \tilde{\X_a}^\trans \tilde{\X_a} \rightarrow \cov{\xv_n},</span>
<span id="cb12-233"><a href="#cb12-233" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-234"><a href="#cb12-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-235"><a href="#cb12-235" aria-hidden="true" tabindex="-1"></a>in contrast to the general case, where </span>
<span id="cb12-236"><a href="#cb12-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-237"><a href="#cb12-237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-238"><a href="#cb12-238" aria-hidden="true" tabindex="-1"></a>\frac{1}{N} \X^\trans \X \rightarrow \expect{\xv_n \xv_n^\trans} = \cov{\xv_n} + \expect{\xv_n}\expect{\xv_n^\trans}.</span>
<span id="cb12-239"><a href="#cb12-239" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb12-240"><a href="#cb12-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-241"><a href="#cb12-241" aria-hidden="true" tabindex="-1"></a>For this reason, when thinking about the sampling behavior of OLS coefficients where a constant</span>
<span id="cb12-242"><a href="#cb12-242" aria-hidden="true" tabindex="-1"></a>is included in the regression, it's enough to think about the covariance of the regressors,</span>
<span id="cb12-243"><a href="#cb12-243" aria-hidden="true" tabindex="-1"></a>rather than the outer product.</span>
<span id="cb12-244"><a href="#cb12-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-245"><a href="#cb12-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-246"><a href="#cb12-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-247"><a href="#cb12-247" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning title='Exercise'} </span>
<span id="cb12-248"><a href="#cb12-248" aria-hidden="true" tabindex="-1"></a>Derive our simple least squares estimator of $\betavhat$ using the</span>
<span id="cb12-249"><a href="#cb12-249" aria-hidden="true" tabindex="-1"></a>FWL theorem.</span>
<span id="cb12-250"><a href="#cb12-250" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb12-251"><a href="#cb12-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-252"><a href="#cb12-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-253"><a href="#cb12-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-254"><a href="#cb12-254" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data visualization</span></span>
<span id="cb12-255"><a href="#cb12-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-256"><a href="#cb12-256" aria-hidden="true" tabindex="-1"></a>The FWL theorem can be useful for data visualization.  Consider using our</span>
<span id="cb12-257"><a href="#cb12-257" aria-hidden="true" tabindex="-1"></a>births dataset to investigate the relationship between smoking and baby birth weight.</span>
<span id="cb12-258"><a href="#cb12-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-261"><a href="#cb12-261" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-262"><a href="#cb12-262" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb12-263"><a href="#cb12-263" aria-hidden="true" tabindex="-1"></a><span class="co">#| display: false</span></span>
<span id="cb12-264"><a href="#cb12-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-265"><a href="#cb12-265" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb12-266"><a href="#cb12-266" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb12-267"><a href="#cb12-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-268"><a href="#cb12-268" aria-hidden="true" tabindex="-1"></a>births_df <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"../datasets/births/births14.csv"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb12-269"><a href="#cb12-269" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(weight), <span class="sc">!</span><span class="fu">is.na</span>(fage), <span class="sc">!</span><span class="fu">is.na</span>(sex), <span class="sc">!</span><span class="fu">is.na</span>(whitemom), <span class="sc">!</span><span class="fu">is.na</span>(habit))</span>
<span id="cb12-270"><a href="#cb12-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-271"><a href="#cb12-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-272"><a href="#cb12-272" aria-hidden="true" tabindex="-1"></a>Here, <span class="in">`habit`</span> is a one-hot indicator for whether a mother smokes, and <span class="in">`weight`</span></span>
<span id="cb12-273"><a href="#cb12-273" aria-hidden="true" tabindex="-1"></a>refers to the birthweight of the baby. The following two regressions give different </span>
<span id="cb12-274"><a href="#cb12-274" aria-hidden="true" tabindex="-1"></a>answers.  </span>
<span id="cb12-275"><a href="#cb12-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-278"><a href="#cb12-278" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-279"><a href="#cb12-279" aria-hidden="true" tabindex="-1"></a>lm_base <span class="ot">&lt;-</span> <span class="fu">lm</span>(weight <span class="sc">~</span> habit, births_df, <span class="at">y=</span><span class="cn">TRUE</span>)</span>
<span id="cb12-280"><a href="#cb12-280" aria-hidden="true" tabindex="-1"></a>lm_inter <span class="ot">&lt;-</span> <span class="fu">lm</span>(weight <span class="sc">~</span> mage <span class="sc">+</span> (habit <span class="sc">+</span> whitemom <span class="sc">+</span> sex)<span class="sc">^</span><span class="dv">2</span>, births_df)</span>
<span id="cb12-281"><a href="#cb12-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-282"><a href="#cb12-282" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_base)<span class="sc">$</span>coefficients</span>
<span id="cb12-283"><a href="#cb12-283" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_inter)<span class="sc">$</span>coefficients</span>
<span id="cb12-284"><a href="#cb12-284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-285"><a href="#cb12-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-286"><a href="#cb12-286" aria-hidden="true" tabindex="-1"></a>The base regression can be visualized with a simple histogram.</span>
<span id="cb12-287"><a href="#cb12-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-290"><a href="#cb12-290" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-291"><a href="#cb12-291" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb12-292"><a href="#cb12-292" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(births_df) <span class="sc">+</span></span>
<span id="cb12-293"><a href="#cb12-293" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x=</span>weight, <span class="at">y=</span>..density.., <span class="at">group=</span>habit, <span class="at">fill=</span>habit), </span>
<span id="cb12-294"><a href="#cb12-294" aria-hidden="true" tabindex="-1"></a>                 <span class="at">alpha=</span><span class="fl">0.5</span>, <span class="at">position=</span><span class="st">"identity"</span>) <span class="sc">+</span></span>
<span id="cb12-295"><a href="#cb12-295" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Birth weight"</span>)</span>
<span id="cb12-296"><a href="#cb12-296" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-297"><a href="#cb12-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-298"><a href="#cb12-298" aria-hidden="true" tabindex="-1"></a>It makes sense that the second one is somehow controlling for other variables,</span>
<span id="cb12-299"><a href="#cb12-299" aria-hidden="true" tabindex="-1"></a>but how can we visualize this?  </span>
<span id="cb12-300"><a href="#cb12-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-301"><a href="#cb12-301" aria-hidden="true" tabindex="-1"></a>Using the FWL theorem, we know that the regression in the second case is</span>
<span id="cb12-302"><a href="#cb12-302" aria-hidden="true" tabindex="-1"></a>equivalent to first projecting orthogonal to all the other regressors,</span>
<span id="cb12-303"><a href="#cb12-303" aria-hidden="true" tabindex="-1"></a>and then looking at the two group means.  We can project orthongal</span>
<span id="cb12-304"><a href="#cb12-304" aria-hidden="true" tabindex="-1"></a>with another regression that *excludes* <span class="in">`habit`</span>:</span>
<span id="cb12-305"><a href="#cb12-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-308"><a href="#cb12-308" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-309"><a href="#cb12-309" aria-hidden="true" tabindex="-1"></a>proj_perp <span class="ot">&lt;-</span> <span class="fu">lm</span>(weight <span class="sc">~</span> mage <span class="sc">+</span> (habit <span class="sc">+</span> whitemom <span class="sc">+</span> sex)<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> habit, births_df)</span>
<span id="cb12-310"><a href="#cb12-310" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(proj_perp)<span class="sc">$</span>coefficients <span class="co"># Smoker is missing</span></span>
<span id="cb12-311"><a href="#cb12-311" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-312"><a href="#cb12-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-315"><a href="#cb12-315" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-316"><a href="#cb12-316" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span></span>
<span id="cb12-317"><a href="#cb12-317" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>